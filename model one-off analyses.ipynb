{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from pprint import pformat\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colorbar as colourbar\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import Divider, Size\n",
    "import matplotlib.colors as colours\n",
    "from copy import copy\n",
    "%matplotlib inline\n",
    "\n",
    "from geodesic_agent import GeodesicAgent\n",
    "from reward_agent import RewardAgent\n",
    "from gridworld import Arena, Bottleneck, LinearChamber, GridWorld\n",
    "from graph import CommunityGraph\n",
    "from plot_utils import plot_replay, plot_traj, plot_need_gain, plot_state_metric\n",
    "from graph_utils import betweenness_centrality, resolvent_centrality\n",
    "from RL_utils import oned_twod, twod_oned\n",
    "\n",
    "def dict_print(d, indent_size=1):\n",
    "    '''\n",
    "        Fancy printing. Collapse identical, consecutive rows in input dictionary d.\n",
    "    '''\n",
    "    indent = ' ' * indent_size\n",
    "    for kdx, key in enumerate(d.keys()):\n",
    "        val = d[key]\n",
    "        if kdx == 0: # No previous one to compare to\n",
    "            prev_val = val\n",
    "            start = kdx\n",
    "            continue\n",
    "        \n",
    "        if val == prev_val: # Consecutive, skip\n",
    "            continue\n",
    "        \n",
    "        # Non-consecutive, print out\n",
    "        if kdx - 1 == start:\n",
    "            print_key = '%d' % start\n",
    "        else:\n",
    "            print_key = '%d-%d' % (start, kdx - 1)\n",
    "        \n",
    "        print(indent + '%s: %s' % (print_key, prev_val))\n",
    "        \n",
    "        # Update\n",
    "        start = kdx\n",
    "        prev_val = val\n",
    "    \n",
    "    if kdx - 1 == start:\n",
    "        print_key = '%d' % start\n",
    "    else:\n",
    "        print_key = '%d-%d' % (start, kdx - 1)\n",
    "\n",
    "    print(indent + '%s: %s' % (print_key, prev_val))\n",
    "    \n",
    "def plot_Tmaze_replay(replayed_experiences, width, height, gw, savename=None, overlap_adjust=0.15, ax=None):\n",
    "\n",
    "    # Generic setup\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "    ax.set_xlim(2, width + 0.5)\n",
    "    ax.set_ylim(height + 0.5, -0.5)  # Puts origin at top left\n",
    "    ax.xaxis.tick_top()  # Puts x-axis ticks on top\n",
    "    plt.axis('off')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # Draw walls\n",
    "    for wall in gw.blocked_paths:\n",
    "        state, action = wall\n",
    "        row, col = oned_twod(state, width, height)\n",
    "        if col == width - 1 and row != 0:\n",
    "            continue\n",
    "\n",
    "        if row == height - 1 and col != width // 2:\n",
    "            continue\n",
    "\n",
    "        if action == 0:  # Block left wall\n",
    "            ax.plot([col, col], [row, row + 1], color='k')\n",
    "        elif action == 1:  # Block top wall\n",
    "            ax.plot([col, col + 1], [row, row], color='k')\n",
    "        elif action == 2:  # Block right wall\n",
    "            ax.plot([col + 1, col + 1], [row, row + 1], color='k')\n",
    "        else:  # Block bottom wall\n",
    "            ax.plot([col, col + 1], [row + 1, row + 1], color='k')\n",
    "\n",
    "    # Draw grid lines in the maze\n",
    "    for y in range(height):\n",
    "        ax.plot([width // 2, width // 2 + 1], [y, y], alpha=0.35, color='gray', linewidth=0.5)\n",
    "\n",
    "    for x in range(width):\n",
    "        ax.plot([x, x], [0, 1], alpha=0.35, color='gray', linewidth=0.5)\n",
    "\n",
    "    # Plot the replayed experiences\n",
    "    ## Now add arrows for replayed states\n",
    "    # Colours!\n",
    "    arrow_colours = plt.cm.winter(np.linspace(0, 1, replayed_experiences.shape[0]))\n",
    "    CENTRE_OFFSET = 0.5  # oned_twod gives the coordinate of the top left corner of the state\n",
    "    for i in range(replayed_experiences.shape[0]):\n",
    "        # Get plotting coordinates\n",
    "        start, action, successor = replayed_experiences[i, :]\n",
    "        start_y, start_x = np.array(oned_twod(start, gw.width, gw.height)) + CENTRE_OFFSET\n",
    "        succ_y, succ_x = np.array(oned_twod(successor, gw.width, gw.height)) + CENTRE_OFFSET\n",
    "        if i == 1:\n",
    "            start_x -= overlap_adjust\n",
    "        if i > 1 and i <= 5:\n",
    "            start_x -= overlap_adjust\n",
    "            succ_x -= overlap_adjust\n",
    "        if i == 9:\n",
    "            start_x += overlap_adjust\n",
    "        if i > 9:\n",
    "            start_x += overlap_adjust\n",
    "            succ_x += overlap_adjust\n",
    "\n",
    "        # Plot\n",
    "        ax.arrow(start_x, start_y, succ_x - start_x, succ_y - start_y,\n",
    "                 length_includes_head=True, head_width=0.25, color=arrow_colours[i])\n",
    "\n",
    "    # Add colour bar\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.1)\n",
    "    cbar = colourbar.ColorbarBase(cax, cmap=plt.cm.winter, orientation='vertical', ticks=[0, 1])\n",
    "    cbar.ax.set_yticklabels(['start', 'end'])\n",
    "    \n",
    "    if savename:\n",
    "        plt.savefig(savename, transparent=True)\n",
    "        \n",
    "def get_fixed_size_figax(nrow, ncol, figsize=(18, 6), fhsize=5, fvsize=3.5):\n",
    "    fh = Size.Fixed(fhsize)\n",
    "    fv = Size.Fixed(fvsize)\n",
    "\n",
    "    fig, axes = plt.subplots(nrow, ncol, figsize=figsize)\n",
    "    h = [fh] * ncol\n",
    "    v = [fv] * nrow\n",
    "    divider = Divider(fig, (0.0, 0.0, 1., 1.), h, v)\n",
    "    if nrow == 1 and ncol == 1:\n",
    "        axes.set_axes_locator(divider.new_locator(nx=0, ny=0))\n",
    "    elif nrow == 1:\n",
    "        for j in range(ncol):\n",
    "            axes[j].set_axes_locator(divider.new_locator(nx=j, ny=0))\n",
    "    elif ncol == 1:\n",
    "        for i in range(nrow):\n",
    "            axes[i].set_axes_locator(divider.new_locator(nx=0, ny=i))\n",
    "    else:\n",
    "        for i in range(nrow):\n",
    "            for j in range(ncol):\n",
    "                axes[i,j].set_axes_locator(divider.new_locator(nx=j, ny=i))\n",
    "                \n",
    "    return fig, axes\n",
    "\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colours.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    \n",
    "    return new_cmap\n",
    "\n",
    "\n",
    "mpl.rcParams.update({'font.size': 25})\n",
    "mpl.rcParams.update({'font.family': 'Arial'})\n",
    "\n",
    "FONT_BG = 25\n",
    "mpl.rcParams['pdf.fonttype'] = 42 # allow text of pdf to be edited in illustrator\n",
    "\n",
    "mpl.rcParams[\"axes.spines.right\"] = False\n",
    "mpl.rcParams[\"axes.spines.top\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Physics\n",
    "width = 10\n",
    "height = 7\n",
    "num_states = width * height\n",
    "\n",
    "# Build object\n",
    "one_start_state = np.zeros(num_states)\n",
    "one_start_state[0] = 1\n",
    "all_start_states = np.ones(num_states) / num_states\n",
    "init_state_dist = one_start_state\n",
    "\n",
    "goal = 36\n",
    "rvec = np.zeros(num_states)\n",
    "rvec[goal] = 1 \n",
    "\n",
    "# Build some walls\n",
    "walls = [(goal, 1), (goal, 2), (goal, 3), (goal - 1, 1), (goal - 1, 3), (goal - 2, 1), (goal - 2, 3)]\n",
    "walls.extend([(goal - 3, 1), (goal - 3, 3)])\n",
    "\n",
    "arena = GridWorld(width, height, init_state_distribution=init_state_dist, walls=walls, term_states=[goal])\n",
    "all_experiences = arena.get_all_transitions(rvec=rvec)\n",
    "T = arena.transitions\n",
    "\n",
    "## Agent parameters\n",
    "alpha = 1.0\n",
    "gamma = 0.95\n",
    "\n",
    "# Set up agent\n",
    "ra = RewardAgent(arena.num_states, arena.num_actions, T, s0_dist=init_state_dist, alpha=alpha, gamma=gamma)\n",
    "ra.curr_state = 0\n",
    "\n",
    "num_steps = 10000\n",
    "for t in range(num_steps):\n",
    "    rand_act = np.random.choice(4)\n",
    "    successor, reward = arena.step(ra.curr_state, action=rand_act, reward_vector=rvec)\n",
    "    \n",
    "    # Learn\n",
    "    ra.basic_learn((ra.curr_state, rand_act, successor, reward))\n",
    "    \n",
    "    # Update\n",
    "    if reward > 0:\n",
    "        ra.curr_state = np.random.choice(num_states)\n",
    "        while ra.curr_state == goal:\n",
    "            ra.curr_state = np.random.choice(num_states)\n",
    "    else:\n",
    "        ra.curr_state = successor\n",
    "\n",
    "# Get state values from Q-values\n",
    "V = np.zeros(num_states)\n",
    "for i in range(num_states):\n",
    "    if i != goal:\n",
    "        V[i] = np.max(ra.Q[i, :])\n",
    "V[goal] = 1 # identically, the reward value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figure 1a, reward and value maps for a particular enclosure*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAFECAYAAAAOSAlUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaOklEQVR4nO3dfbRdaV0f8O9vbnIzmWQmk5DcOwzlRaqiqPWFaqEjlQ7YpeBLrYhVUWmxdVRYutRWV6uCpVWs1ipI1UoRX2itoraCtlUcWFK0IlQErajImwLembnJzJBJZnKT+/SPve/cM5d7M3mSObOTyeez1l53n3Oes397JzfP+eY5z967WmsBAADOzRVT7wAAAFxKBGgAAOggQAMAQAcBGgAAOgjQAADQQYAGAIAOAjT3qqpXVlU7h2Wtqo5W1dur6hVVdcPU+36pq6qnzPz5Pmfq/QEubVX16gvpU6rqC2fe/x8ucF9mP1uuu5BtwcVCgOZ87EpyMMknJflHSf53Vb1k2l0CYMZPzqx/+Xm8/9k7bAvIEIRgO/8kyVt2eG1Pkkcl+YIkX5Gkkjy/qv68tfbDD9L+AbCz/5nkQ0kenuTGqlpura2cyxur6toknz8+/MPW2u/NZxfh0mUEmp28q7X2th2W322t/UJr7SuTPCvJxu0sv6OqrpxwnwFI0lo7k+Rnx4cLGfrqc/UlGQZKkuQVD+R+wUOFAM0Faa29OsmvjA8PJ3nqhLsDwKbZqRdf1vG+rxx/rmUzhAMzBGgeCL85s/7Rk+0FAPdqrf1xkt8dHz6pqj7q/t5TVY9J8pnjw9e01m6d0+7BJU2A5oGwMLO+e7sGVfXxVfWyqnpnVR2vqrvG9R+tqsdv0/65M2dtf9EO27xxps1rdtq5qvrLsc3PbfPa36iqf19Vb62qW6vqVFXdPu7by6vq03fY5uxVMz6lqp5eVb9fVXeP2/nNqrp+y3ueXFW/UFXvHtu9t6peurUdwAOodxT62RnOa9n63lTVM6rqJ8f+8dh4Rabbqur3qurFVfXXendu7AdbVb3zftodH9u94SxtDlXVC6rqzeOVou6uqvdX1c9X1ef27hucjQDNA+HvzKz/ydYXq+o7krwjydcneVySfUmuGtdvSvKOqnphVdXM2341m3OrP3uHuk+bWX9yVS1sbVBVn5zkEePDX5l5fqGqXprkbUm+KcmnZZiCsjvJgXHfnpvkzVX1bTvU3/D0JK9J8ikZ5g0eTvKYDCfwpKquqKqXJfmtJM9M8lFju0cneV6SP0zyGfdTA+B8/FySu8f1cw3QydB//Y8kqaqHVdVvJXltkudk6B+vzXAhgocl+ZtJvi3JH1fVjQ/Ujveoqqcn+fMkL0zy6RmuFLUnySMzzOn+tar671V19RT7x0OPAM0FqaqnZbgaR5LclvtO50hVvTDJizKMUv9xhsB4w7g8L8mfZvg9fMG4JElaa3+V5K3jw3MJ0AeSfOo2bZ4+/jyd8cNg9F1j/coQ+p+XYf72DRmuLPJrM22/Z7tR8hkvSnLHzLHdlORFrbWN/wD82wz/eUiS946vPynJ5yX5+Qwd/feeZfsA56W1dkeSXx4ffmJVfdJObcdv3B43Pvzp8UTEJPnFJE8e11+XIWQ/OUOfeVOSPxpf25/kp7YbzJinqnpqhgGSa5OsJvlX4749MUN//rqx6Rck+eUHe/94iGqtWSxprSXJKzOM+rYkT9mhzUKSQxlGTL83w8jGxnu+ekvbT0tyZnzt1UkWt9ne3gydW0uynuTxM6+9YGbbj9nyvmtntn1q/Pmt22z/jeNrN888d3WSk+Pz705yaIdj/YGZ+t+x5bWnzLzWknz2Dtv4+Awn4rQMo/AHt2nzzVu29ZypfxcsFstDZ8kwCLHRv3zPWdq9ZKbd48bnnjbz3C8lqW3et5Dk/8y0+8wtr89+tly35bX3js+/836O4fjY7g1bnt+bYbS8ZRgMuX6H9/+bmX24aeq/E8ulvxiBZiev3+4uhBlGclcznJjy7Rm+IjuZ5Otbaz+1ZRvfkmF0+XiS57bWTm0t0lo7meQfZwjPleT5My+/dmZ96yj0jeO2b8lwvdNkCLX3Gq9l+sTx4a/MvPSJSd6T5ESSH2qtHd3uDyD3Pfv8ETu0SZI/b639xg6vPTeb11u/qbV2bGuD1toPZpjeATAPv5nkL8b1badxVNWuJP9wfPim1trGdLzHZegv15K8sLXWtr63DSPVs+eYnK2/fKA9O8nG3Q2/rrX2wR3afVc2pxh+49z3ioc8AZrzdU+SNyf57iQf21r70dkXx/nMGydtvLkNXyNuq7X2/gzzgJP7Xgbv/ybZ6Ay3BuiN6RtvSPLb4/rWedB/L5vh9d4A3Vr7ndba41tr+5L8yE77leSvZtb37NhqGHnZycYUkve31t50lnautQrMRWttPclPjw8fU1V/e5tmn5PkyLh+b3/UWntZa+2xSa5srb39LGXOtb98oD1j/LmW4fNgW2PI/1/jw49z8jYXyp0I2cnWOxHuyzBt459n+N/+3Un+c5KXbDcikeEkuoPj+o3j6PW5uPcyS621VlW/luRrkjy1qq4YPwiSzQB9c5L/N65fk2HayMZdszbC6x+11t69XbGN7VXVw5I8NslfT/L4cTufOdP0bP/Z/IvtnqyqK5J87PjwbWd5fzL8ZwRgXl6Z5F+O61+WzYGHDRvXfr4rw7kZ9zHTV1aS6zP0lx+T5BMynLT3xJnmD+bg3Ma5L7uTnLnvuehn9dhsDtBANwGanbyrtfa2Lc+9abwU3OszfK33Qxnm+N60zfsPn2fdXVV1dWvtw+Pj12YI0IcyhNq3VNUjM3TcGfflvRmmY1yVYRrH742d/OeMbWanb9yrqv5Whq/ynpbNkZdZ69s8t507d3j+Ydm8xN/q/WzjnG6xC3A+Wmvvqqo3Zjj571lV9U3jqGyq6pps3rr7F1prx2ffO/anz8owsPLEDAMqW51rf/lAO9/PmoP33wR2JkDTpbX2oar6vAzTK65O8rVV9d7W2ou3NJ393XpFkpd2lDkxs/4bGUa7r8wQdN+SzekcH2yt/WmSVNVvj68/Jcn3J3lCkuWx3UcE6Kr6zgxnas9ayXClkHdkmJbx+9kc3T6bnUbXz3XUPRm+fgSYp1dmCNBLGabL/fr4/DMznIyXbJlOVlVXZjgJ/BkzT7cM86LfmeHbtTdlGOT4mfnsdpKdR7U3PmvenuSrO7b3ngvbHS53AjTdxpGMb8jmnLoXVdXrWmuzUz5mT8y7cpvR7HOtdWK8cP7nZAjOL85wAmEyjD5vuDlDgN6YB70x/3olm3fiSpKMF9TfCM9/leQ7k/xqa+1DW9o95nz2ecZqhmC8O8MH1tkcusBaAPfn5zNcaWNfki/PZoDemL7xZ621N255z3dnMzy/JUPf+YaZbwmTJFX1nPPcp42Bhh3nXlTV7mwG/K2OZphWePh8P2fgfDiJkPPSWvuZbI7s7kryk2Mnt+Hd2RxJ/qxxPvCOqupbquprx+tKb7VxNY4bquqqJJ81Pr55ps3G+tUZLuq/0eG/dps52t8ws/6lrbWXbw3Po0edbZ/vz1h3YwT7CXX2yXmfciG1AO7PODXj1ePDL6yq3VV1XTZvhrX1zoMLSb52fHh7kqe21l6zNTyPzre/PD3+vOosbc627Y0T0K+vqo89S7tU1TOr6hur6gurartpKHDOBGguxNdlc/7vJ2a4nnGSpLW2ls0R4kdk+IpwW1X1pAzXXP6xJP9imyYbt+nek+SrkmzcLnZ2BPotM/vyJRlOakm2n//80TPrb93m9Q3Pnlk/329rfnH8eV3u+xXoVl91ntsH6LERkq/NMOXtizJkgTPZ/FZxw5EMN6lKhvNitj3fYxw8edbMUz395e3jz6Wq2mmU+ek7PJ9sXlkjGe4qu60xMP94hnN3XpW+KXbwEQRoztt4vc3vnHnqu7ZMe/h3M+s/st3d/KrqYJL/NPPUS7apM3uZu42zyN/XWnvPTJsz2byW8jdk+N0+mc07UM26bWb9c7d5PVX13AwnL24438syvSKbwf5lVfURIylV9eVJ/sF5bh+gx29l+IYwSf5+ki8e13+9tfaBLW3vyOYI8Sfs0H8tZhj8+ISZp3v6y41L4y1mc7R7dvsfk/t+zmz18mz2sTdV1Zdus41K8hPZnCr38tbaia3toIcAzYV6WYYTCpPhK7iXbbzQWnt9ko3rQx9J8uaqenFV3VhVT66q52c4AeXjxza/3Fr7bzvU2ZjGsTH6fPM2bTaeu3L8+bodOsnZSzS9oqpeUFVPraobquo5VfW6DJ3y7JSLAzkP4wfSPxsfPirJW6vqW6vqSVX12VX1ExlOvLnrfLYP0GOcWrZx06tnZnNK3Edci3680dXGN4B7k7yhqm4a+8obq+qbk/xBhpthzerpL2dPPPz+qvqBqvq74/LdGS7xeTDJ+3Y4ntuT/NPxYSX5L1X1qqr6/Kp6YlV9RYaTHDduIPOeJC/s2D/Y3tS3QrRcPEvO4VbeO7zvM7J5W+2W5Jkzry0k+cEMlzhqZ1l+Mcnes9S4YUv7r9ymzSdvafM1O2xrV4ZAfrb9OZPk+zKcgNiSfGDLNp4y0/bbz+HP6Plb/oxmlxNJvnTm8XOm/l2wWCwP3SXJo7f0ybclWdyh7SMyjFifrb+8I0OIPj0+ftWWbcx+tly3TY3vO8u2784wxe3V2eZW3jPb+IoMAxFn288/TPJRU//5Wx4aixFoLlhr7c1J/uPMUz88Xlc0rbUzrbVvznCx+x/LcNmj4xmuTvGBDMH5Ga21L27DaMdOfif3nXrx+m3avH2mTct9bwU+u7+nk3xBhq8L35ih8z+T4WvAd2QYNf/U1tq3ZfMs9eur6oaz7N9ZtdZemmGe+MuT/FmGD4UPZZiL94QMt9oFmLvW2vty32/xfra1dmqHth/IcA3+f52hfzyZISivZuiXX5jkca21V4yPk+TpPSfpjX3tU5P8UoYrJ51K8v4M87Wf0FrbOjd7u228KsPNUV6U4WZax2b28+YM9yv4tDYz9Q8uRLVmHj0AAJwrI9AAANBBgAYAgA4CNAAAdBCgAQCggwANAAAdBGgAAOggQAMAQAcBGgAAOgjQAADQQYAGAIAOAjQAAHQQoAEAoIMADQAAHQRoAADoIEADAEAHARoAADoI0AAA0EGABgCADgI0AAB0EKABAKCDAA0AAB0EaAAA6CBAAwBABwEaAAA6CNAAANBBgAYAgA4CNAAAdBCgAQCggwANAAAdBGgAAOggQAMAQAcBGgAAOgjQAADQQYAGAIAOAjQAAHQQoAEAoIMADQAAHQRoAADoIEADAEAHARoAADoI0AAA0EGABgCADgI0AAB0EKABAKCDAA0AAB0EaAAA6CBAAwBABwEaAAA6CNAAANBBgAYAgA4CNAAAdNg1z41XVZvn9gEuFq21mnofeuifgcvFPPrnuQboJGltmj56ZWUly8vLk9Seur5jd+yXW/2pj73qksrO9zr9X39gkrq3/OUHs7SwPkntJFlZOZalds8ktW89cv2kx37LwYdn6cqFaWpfdShL+/ZMUjtJbtl9TZYP7J+m9vqeLB86MEntJLnlxOksHz40Se2V4/dk+cjhSWonSe27di7bNYUDAAA6CNAAANBBgAYAgA4CNAAAdBCgAQCggwANAAAdBGgAAOggQAMAQAcBGgAAOgjQAADQQYAGAIAOAjQAAHQQoAEAoIMADQAAHQRoAADoIEADAEAHARoAADoI0AAA0EGABgCADgI0AAB0EKABAKCDAA0AAB0EaAAA6CBAAwBABwEaAAA6CNAAANBBgAYAgA4CNAAAdBCgAQCgw655F1hZWZl3iW2trq5OUvdiqO/Yp+PYL7/al7Jb/vKDk9RdXb0zra1NUjtJbj16ImfWTk5S+44rpj32Y6d2JQvrk9Q+es1asjjduN3RvQeS2xenqb1rf9qHp+unjq4vpt191zS17z6dTFR7nuYeoJeXl+dd4qKsPXV9xz4dx3751b5ULU0UpFpby1K7Z5LaSXJm7WSOnJrmA31h4mOvhfXJ/t6zeEWWrlyYpnaS7F3M0r4909TevTfLB/ZPUztJre/J8qED09Q+cTrLhw9NUnueTOEAAIAOAjQAAHQQoAEAoIMADQAAHQRoAADoIEADAEAHARoAADoI0AAA0EGABgCADgI0AAB0EKABAKCDAA0AAB0EaAAA6CBAAwBABwEaAAA6CNAAANBBgAYAgA4CNAAAdBCgAQCggwANAAAdBGgAAOggQAMAQAcBGgAAOgjQAADQQYAGAIAOAjQAAHQQoAEAoIMADQAAHQRoAADoIEADAECHXfMusLKyMu8S21pdXZ2k7sVQ37FPx7FffrUvZSsrxyape+vREzmzdnKS2kmycmwtp06emqT28X3THvsdV9yZ1tYmqX3s1K5kYX2S2kly9Jq1ZHGaccOjew8kty9OUjtJju7an/bhafrJo+uLaXffNUnteZp7gF5eXp53iYuy9tT1Hft0HPvlV/tStdTumaTumbWTOXJqug/UUydP5fBdd05Se3Ht4KTHvtDWJvt7r4X1LE0YoLN4RZauXJim9t7FLO3bM03tJNm9N8sH9k9Sutb3ZPnQgUlqz5MpHAAA0EGABgCADgI0AAB0EKABAKCDAA0AAB0EaAAA6CBAAwBABwEaAAA6CNAAANBBgAYAgA4CNAAAdBCgAQCggwANAAAdBGgAAOggQAMAQAcBGgAAOgjQAADQQYAGAIAOAjQAAHQQoAEAoIMADQAAHQRoAADoIEADAEAHARoAADoI0AAA0EGABgCADgI0AAB0EKABAKDDrql3gAdWVU29C0yotTb1LgA7uPaN70je+I6pd4OJnL75VVPvAg+guQfolZWVeZfY1urq6iR1L5b6XJ6m+veWTPs779/b+fnQLccnqbtybC2nTp6apHaSvOeeXbnt5O7J6nN5umX3NZPVPrq+mFrfM03tu0+nTpyepPY8zT1ALy8vz7vERVl7qvqttaysrEx67FPWn/rYn7f82Jy+5bYHve6P58NJLs/f+Yuh9qXqyKm7Jql76uSpHL7rzklqJ8ltJ3fn2ttvf9DrvvOjH5s/WdibfavHHvTaG/5k/9XZfds0/+H8g6uunqR/3LBr6fC0/fOB/Q967Q21vifLhw5MU/vE6SwfPjRJ7XkyBxoAADoI0AAA0EGABgCADgI0AAB0EKABAKCDAA0AAB0EaAAA6CBAAwBABwEaAAA6CNAAANBBgAYAgA4CNAAAdBCgAQCggwANAAAdBGgAAOggQAMAQAcBGgAAOgjQAADQQYAGAIAOAjQAAHQQoAEAoIMADQAAHQRoAADoIEADAEAHARoAADoI0AAA0EGABgCADgI0AAB0EKABAKDDrql3gAdWVU29CwBs4+Pe9e6pdyG5bcLax6csnuSWD09bn4eUuQfolZWVeZfY1urq6iR1L5b6XJ6m+veWTPs779/b+Tn6yEdNUvf4vhNZXDs4Se0kWTi2ll2H9z74hS+GAM1kVt73nslqH921P+3D0/STR9cX0+6+a5La8zT3AL28vDzvEhdl7anqt9aysrIy6bFPWd+xX36/8xdD7UvVUrtnkrpn1k7myKnpPlBPnTyVw3fd+aDXvf3Jn5Q7P+bRkx770Uc+arK/91uPXJ+lhfVJaifJLQcfnqUrF6apfdWhLO3bM0ntJMnuvVk+sH+S0rW+J8uHDkxSe57MgQYAgA4CNAAAdBCgAQCggwANAAAdBGgAAOggQAMAQAcBGgAAOgjQAADQQYAGAIAOAjQAAHQQoAEAoIMADQAAHQRoAADoIEADAEAHARoAADoI0AAA0EGABgCADgI0AAB0EKABAKCDAA0AAB0EaAAA6CBAAwBABwEaAAA6CNAAANBBgAYAgA4CNAAAdBCgAQCggwANAAAdBGgAAOiwa94FVlZW5l1iW6urq5PUvRjqO/bpOPbLr/al7NYj109S944r7sxCW5ukdpIc33cii2sHJ6l9x3XXTXrsxw4eSS2sT1L76DVHksXpxu2O7j2Q7F2cpvau/cnuvZPUTpKj64up9T3T1L77dOrE6Ulqz9PcA/Ty8vK8S1yUtaeu79in49gvv9qXqqWJglRra1lq90xSO0nOrJ3MkVN3TVJ7YeJjr4X1yf7es3hFlq5cmKZ2kuxdzNK+aUJkdu/N8oH909ROUut7snzowDS1T5zO8uFDk9SeJ1M4AACggwANAAAdBGgAAOggQAMAQAcBGgAAOgjQAADQQYAGAIAOAjQAAHQQoAEAoIMADQAAHQRoAADoIEADAEAHARoAADoI0AAA0EGABgCADgI0AAB0EKABAKCDAA0AAB0EaAAA6CBAAwBABwEaAAA6CNAAANBBgAYAgA4CNAAAdBCgAQCggwANAAAdBGgAAOggQAMAQAcBGgAAOgjQAADQYde8C6ysrMy7xLZWV1cnqXsx1Hfs03Hsl1/tS9ktBx8+Sd1jp3alFtYnqZ0kd1xxZxba2iS1jx08MumxH73mSLI4zdjZ0b0Hkr2Lk9ROkqO79ie7905Te30xtb5nktpJcvTu06kTpyepvXryVHL8nklqz9PcA/Ty8vK8S1yUtaeu79in49gvv9qXqqUrF6YpvLCepQlDZGtrWWrTfKDXxMeexSum+3vfu5ilfdOFyOzem+UD+ycpXet7snzowCS1k6ROnM7y4UPTFD9+T5aPHJ6m9hyZwgEAAB0EaAAA6CBAAwBABwEaAAA6CNAAANBBgAYAgA4CNAAAdBCgAQCggwANAAAdBGgAAOggQAMAQAcBGgAAOgjQAADQQYAGAIAOAjQAAHQQoAEAoIMADQAAHQRoAADoIEADAEAHARoAADoI0AAA0EGABgCADgI0AAB0EKABAKCDAA0AAB0EaAAA6CBAAwBABwEaAAA6CNAAANChWmvz23jV/DYOcBFprdXU+9BD/wxcLubRP881QAMAwEONKRwAANBBgAYAgA4CNAAAdBCgAQCggwANAAAdBGgAAOggQAMAQAcBGgAAOgjQAADQQYAGAIAOAjQAAHQQoAEAoIMADQAAHQRoAADoIEADAEAHARoAADoI0AAA0EGABgCADgI0AAB0EKABAKCDAA0AAB3+P9hWrQyAXGTNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow = 1\n",
    "ncol = 2\n",
    "fig, axes = get_fixed_size_figax(nrow, ncol)\n",
    "\n",
    "# Reward\n",
    "ax = axes[0]\n",
    "rvec = np.zeros(num_states)\n",
    "rvec[goal] = 1\n",
    "\n",
    "gridworld = arena\n",
    "metric = rvec\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_axis_off()\n",
    "gridworld.draw(use_reachability=True, ax=ax)\n",
    "\n",
    "# Grab boundaries\n",
    "min_metric = 0.0001  # Dumb hack so that metric = 0 states don't appear slightly red\n",
    "max_metric = np.max(rvec)\n",
    "\n",
    "metric_cols = colours.Normalize(vmin=min_metric, vmax=max_metric)(rvec)\n",
    "\n",
    "# Build custom palette without dumb red bottom boundary\n",
    "palette = copy(plt.get_cmap('Reds'))\n",
    "palette.set_under('white', 1.0)\n",
    "\n",
    "# Get colours for each state\n",
    "state_colours = palette(metric_cols).reshape(-1, 4)\n",
    "for state in range(gridworld.num_states):\n",
    "    if hasattr(gridworld, 'banned_states') and state in gridworld.banned_states:\n",
    "        continue\n",
    "    row, col = oned_twod(state, gridworld.width, gridworld.height)\n",
    "    rect = patches.Rectangle((col, row), 1, 1, facecolor=state_colours[state])\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "ax.set_title('Reward')\n",
    "\n",
    "# Value\n",
    "ax = axes[1]\n",
    "plot_state_metric(arena, V, save=False, savename='./figs/fig1/1r_walls_Qmap.pdf', wall_width=2, ax=ax)\n",
    "ax.set_title('Value')\n",
    "\n",
    "# Save\n",
    "fig.savefig('./figs/fig1/1_Qr_map.pdf', transparent=True, bbox_inches=0, pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fig 1e, need, gain, and EVB maps for an open field environment -- before learning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physics\n",
    "width = 10\n",
    "height = 7\n",
    "num_states = width * height\n",
    "\n",
    "# Build object\n",
    "one_start_state = np.zeros(num_states)\n",
    "one_start_state[0] = 1\n",
    "all_start_states = np.ones(num_states) / num_states\n",
    "init_state_dist = one_start_state\n",
    "\n",
    "arena = Arena(width, height, init_state_distribution=init_state_dist)\n",
    "all_experiences = arena.get_all_transitions()\n",
    "T = arena.transitions\n",
    "\n",
    "## Agent parameters\n",
    "corner_goals = np.array([width - 1, (height - 1) * width, height * width - 1]) # Non-start corners\n",
    "all_goals = np.arange(0, width * height)\n",
    "goals = corner_goals\n",
    "\n",
    "alpha = 1.0\n",
    "gamma = 0.95\n",
    "num_replay_steps = 1\n",
    "\n",
    "# Set up agent\n",
    "ga = GeodesicAgent(arena.num_states, arena.num_actions, goals, T, alpha=alpha, gamma=gamma,\n",
    "                   s0_dist=init_state_dist)\n",
    "ga.curr_state = 0\n",
    "ga.remember(all_experiences) # Pre-load our agent with all possible memories\n",
    "\n",
    "## Run replay\n",
    "replayed_experiences, stats_for_nerds, backups = ga.replay(num_steps=num_replay_steps, verbose=True, prospective=True)\n",
    "needs, trans_needs, gains, all_MEVBs = stats_for_nerds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the replayed experiences\n",
    "cmap = plt.get_cmap('Purples')\n",
    "trunc_purples = truncate_colormap(cmap, 0.2, 0.8)\n",
    "\n",
    "print('First %d replay steps' % num_replay_steps, flush=True)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "plot_replay(arena, np.array(replayed_experiences).astype(int), ax=ax)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.axis('off')\n",
    "ax.scatter(0.5, 0.5, marker='x', color='r')\n",
    "plt.show()\n",
    "\n",
    "# Plotting params\n",
    "# params = {'min_need' : 0,\n",
    "#           'max_need' : 1,\n",
    "#           'alpha_fac' : 0.5}\n",
    "params = None\n",
    "\n",
    "# Plot need, gain, MEVB throughout each of those steps\n",
    "meta_need = np.mean(needs, axis=1)\n",
    "meta_gain = np.mean(gains, axis=1)\n",
    "meta_MEVB = np.mean(all_MEVBs, axis=1)\n",
    "verbose = True\n",
    "\n",
    "fig, axes = get_fixed_size_figax(1, 3)\n",
    "# for i in range(num_replay_steps):\n",
    "for i in [0]:\n",
    "    print('step %d:' % i)\n",
    "    if verbose:\n",
    "        print('\\tReplayed transition:', replayed_experiences[i])\n",
    "        print('\\tBackup dictionary:')\n",
    "        dict_print(backups[i], indent_size=8)\n",
    "        print('\\tReplay history:')\n",
    "        for j in range(i):\n",
    "            print('\\t\\t',replayed_experiences[j])\n",
    "\n",
    "    plot_need_gain(arena, ga.memory, np.average(meta_need[i, :, :], weights=init_state_dist, axis=0), \n",
    "                   meta_gain[i, :], meta_MEVB[i, :], specials=None, params=params, fig=fig, axes=axes,\n",
    "                   custom_need_cmap=trunc_purples)\n",
    "    plt.savefig('./figs/fig1/needgainevb_pre.pdf', transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fig 1e, need, gain, and EVB maps for an open field environment -- after learning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physics\n",
    "width = 10\n",
    "height = 7\n",
    "num_states = width * height\n",
    "\n",
    "# Build object\n",
    "one_start_state = np.zeros(num_states)\n",
    "one_start_state[0] = 1\n",
    "all_start_states = np.ones(num_states) / num_states\n",
    "init_state_dist = one_start_state\n",
    "\n",
    "arena = Arena(width, height, init_state_distribution=init_state_dist)\n",
    "all_experiences = arena.get_all_transitions()\n",
    "T = arena.transitions\n",
    "\n",
    "## Agent parameters\n",
    "corner_goals = np.array([width - 1, (height - 1) * width, height * width - 1]) # Non-start corners\n",
    "all_goals = np.arange(0, width * height)\n",
    "goals = corner_goals\n",
    "\n",
    "alpha = 1.0\n",
    "gamma = 0.95\n",
    "num_replay_steps = 1\n",
    "\n",
    "# Set up agent\n",
    "ga = GeodesicAgent(arena.num_states, arena.num_actions, goals, T, alpha=alpha, gamma=gamma,\n",
    "                   s0_dist=init_state_dist)\n",
    "ga.curr_state = 0\n",
    "ga.remember(all_experiences) # Pre-load our agent with all possible memories\n",
    "G = arena.solve_GR(10000, gamma)\n",
    "ga.initialize_GR(G)\n",
    "\n",
    "## Run replay\n",
    "replayed_experiences, stats_for_nerds, backups = ga.replay(num_steps=num_replay_steps, verbose=True, \n",
    "                                                           prospective=True, check_convergence=False)\n",
    "needs, trans_needs, gains, all_MEVBs = stats_for_nerds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the replayed experiences\n",
    "print('First %d replay steps' % num_replay_steps, flush=True)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "plot_replay(arena, np.array(replayed_experiences).astype(int), ax=ax)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.axis('off')\n",
    "ax.scatter(0.5, 0.5, marker='x', color='r')\n",
    "plt.show()\n",
    "\n",
    "# Plotting params\n",
    "# params = {'min_need' : 0,\n",
    "#           'max_need' : 1,\n",
    "#           'alpha_fac' : 0.5}\n",
    "params = None\n",
    "\n",
    "# Plot need, gain, MEVB throughout each of those steps\n",
    "# zeroed_needs = zero_needs(needs, goals)\n",
    "zeroed_needs = needs\n",
    "meta_need = np.mean(zeroed_needs, axis=1)\n",
    "meta_gain = np.mean(gains, axis=1)\n",
    "meta_MEVB = np.mean(all_MEVBs, axis=1)\n",
    "verbose = True\n",
    "\n",
    "fig, axes = get_fixed_size_figax(1, 3)\n",
    "# for i in range(num_replay_steps):\n",
    "for i in [0]:\n",
    "    print('step %d:' % i)\n",
    "    if verbose:\n",
    "        print('\\tReplayed transition:', replayed_experiences[i])\n",
    "        print('\\tBackup dictionary:')\n",
    "        dict_print(backups[i], indent_size=8)\n",
    "        print('\\tReplay history:')\n",
    "        for j in range(i):\n",
    "            print('\\t\\t',replayed_experiences[j])\n",
    "\n",
    "    plot_need_gain(arena, ga.memory, np.average(meta_need[i, :, :], weights=init_state_dist, axis=0), \n",
    "                   meta_gain[i, :], meta_MEVB[i, :], specials=None, params=params, fig=fig, axes=axes,\n",
    "                   custom_need_cmap=trunc_purples)\n",
    "    plt.savefig('./figs/fig1/needgainevb_post.pdf', transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2a, asymmetric T-maze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GR*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Physics\n",
    "height = 5\n",
    "width = 9\n",
    "num_states = width * height\n",
    "\n",
    "# Special states\n",
    "start = twod_oned(width // 2, height - 1, width)\n",
    "choice = twod_oned(width // 2, 0, width)\n",
    "near_goal = choice - 2\n",
    "far_goal = choice + 4\n",
    "\n",
    "# Build walls\n",
    "walls = []\n",
    "for h in range(height - 1, 0, -1):\n",
    "    state_x = width // 2\n",
    "    state_y = h\n",
    "    state_id = twod_oned(state_x, state_y, width)\n",
    "\n",
    "    walls.append((state_id, 0))\n",
    "    walls.append((state_id, 2))\n",
    "\n",
    "walls.append((near_goal, 0))\n",
    "walls.append((far_goal, 2))\n",
    "\n",
    "for w in range(near_goal, far_goal + 1):\n",
    "    if w == width // 2:\n",
    "        continue\n",
    "    \n",
    "    walls.append((w, 3))\n",
    "    \n",
    "# Build GridWorld\n",
    "s0_dist = np.zeros(num_states)\n",
    "s0_dist[start] = 1\n",
    "gw = GridWorld(width, height, walls=walls, init_state_distribution=s0_dist)\n",
    "\n",
    "T = gw.transitions\n",
    "all_experiences = gw.get_all_transitions()\n",
    "\n",
    "# Goal distribution\n",
    "goal_dist = np.array([near_goal, far_goal])\n",
    "\n",
    "## Agent parameters\n",
    "alpha = 1.0\n",
    "gamma = 0.95\n",
    "num_replay_steps = 14\n",
    "\n",
    "# Set up agent\n",
    "ga = GeodesicAgent(gw.num_states, gw.num_actions, goal_dist, T, alpha=alpha, gamma=gamma,\n",
    "                   s0_dist=s0_dist)\n",
    "ga.curr_state = start\n",
    "ga.remember(all_experiences) # Pre-load our agent with all possible memories\n",
    "\n",
    "## Run replay\n",
    "replayed_experiences, stats_for_nerds, backups = ga.replay(num_steps=num_replay_steps, verbose=True)\n",
    "needs, trans_needs, gains, all_MEVBs = stats_for_nerds\n",
    "\n",
    "# Plot\n",
    "plot_Tmaze_replay(replayed_experiences, width, height, gw, savename='./figs/fig2/Tmaze_GR_clean.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Mattar*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Physics\n",
    "height = 5\n",
    "width = 9\n",
    "num_states = width * height\n",
    "\n",
    "# Special states\n",
    "start = twod_oned(width // 2, height - 1, width)\n",
    "choice = twod_oned(width // 2, 0, width)\n",
    "near_goal = choice - 2\n",
    "far_goal = choice + 4\n",
    "\n",
    "# Build walls\n",
    "walls = []\n",
    "for h in range(height - 1, 0, -1):\n",
    "    state_x = width // 2\n",
    "    state_y = h\n",
    "    state_id = twod_oned(state_x, state_y, width)\n",
    "\n",
    "    walls.append((state_id, 0))\n",
    "    walls.append((state_id, 2))\n",
    "\n",
    "walls.append((near_goal, 0))\n",
    "walls.append((far_goal, 2))\n",
    "\n",
    "for w in range(near_goal, far_goal + 1):\n",
    "    if w == width // 2:\n",
    "        continue\n",
    "    \n",
    "    walls.append((w, 3))\n",
    "\n",
    "# Goal distribution\n",
    "rvec = np.zeros(num_states)\n",
    "rvec[near_goal] = 1/2\n",
    "rvec[far_goal] = 1/2\n",
    "\n",
    "# Build GridWorld\n",
    "s0_dist = np.zeros(num_states)\n",
    "s0_dist[start] = 1\n",
    "gw = GridWorld(width, height, walls=walls, init_state_distribution=s0_dist, term_states=[near_goal, far_goal])\n",
    "\n",
    "T = gw.transitions\n",
    "all_experiences = gw.get_all_transitions(rvec=rvec)\n",
    "\n",
    "## Agent parameters\n",
    "alpha = 1.0\n",
    "gamma = 0.95\n",
    "num_replay_steps = 14\n",
    "\n",
    "## Agent parameters\n",
    "alpha = 1.0\n",
    "gamma = 0.95\n",
    "num_replay_steps = 14\n",
    "\n",
    "# Set up agent\n",
    "ra = RewardAgent(gw.num_states, gw.num_actions, T, s0_dist=s0_dist, alpha=alpha, gamma=gamma)\n",
    "ra.curr_state = start\n",
    "ra.remember(all_experiences)\n",
    "replays, _, _ = ra.replay(num_replay_steps, verbose=True, prospective=False, conv_thresh=1e-4)\n",
    "\n",
    "plot_Tmaze_replay(np.array(replays[:, :3]).astype(int), width, height, gw, \n",
    "                  savename='./figs/fig2/Tmaze_mattar_clean.pdf', overlap_adjust=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2b, bottleneck chamber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_replay = True\n",
    "num_sims = 200\n",
    "start = 0\n",
    "\n",
    "# Physics\n",
    "room_width = 3\n",
    "corridor_width = 3\n",
    "width = room_width * 2 + corridor_width\n",
    "height = 5\n",
    "num_states = width * height\n",
    "\n",
    "# Build object\n",
    "valid_states = Bottleneck.get_valid_states(room_width, corridor_width, height)\n",
    "\n",
    "all_states = np.zeros(num_states)\n",
    "all_states[valid_states] = 1 / len(valid_states)\n",
    "one_state = np.zeros(num_states)\n",
    "one_state[0] = 1\n",
    "init_state_dist = all_states\n",
    "\n",
    "bottleneck = Bottleneck(room_width, corridor_width, height, init_state_distribution=init_state_dist)\n",
    "all_experiences = bottleneck.get_all_transitions()\n",
    "T = bottleneck.transitions\n",
    "\n",
    "# Agent parameters\n",
    "corner_goals = np.array([width - 1, height * width - 1]) # Non-start corners\n",
    "all_goals = np.arange(num_states)\n",
    "valid_goals = valid_states\n",
    "goals = valid_goals\n",
    "\n",
    "alpha = 1.0\n",
    "gamma = 0.95\n",
    "num_replay_steps = 1000\n",
    "\n",
    "if run_replay:\n",
    "    print('running...')\n",
    "    for i in range(start, num_sims):\n",
    "        print(i, end=', ')\n",
    "        \n",
    "        # Set up agent\n",
    "        ga = GeodesicAgent(bottleneck.num_states, bottleneck.num_actions, goals, T, alpha=alpha, gamma=gamma,\n",
    "                          s0_dist=init_state_dist)\n",
    "        ga.curr_state = 0\n",
    "        ga.remember(all_experiences) # Pre-load our agent with all possible memories\n",
    "\n",
    "        ## Run replay\n",
    "        replayed_exps, stats_for_nerds, backups = ga.replay(num_steps=num_replay_steps, verbose=True, prospective=True)\n",
    "        needs, trans_needs, gains, all_MEVBs = stats_for_nerds\n",
    "        np.savez('./Data/bottleneck/bottleneck_data_small_%d.npz' % i, replayed_exps=replayed_exps, needs=needs,\n",
    "                                                               trans_needs=trans_needs, gains=gains, all_MEVBs=all_MEVBs)\n",
    "    print('ran!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figure 2b, schematic, asymptotic need, and empirical replay distribution in bottleneck chamber*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_sims = 200\n",
    "hmap = np.zeros((num_states, num_sims))\n",
    "for sim in range(num_sims):\n",
    "    d = np.load('./Data/bottleneck/bottleneck_data_small_%d.npz' % sim)\n",
    "    replayed_exps = d['replayed_exps']\n",
    "    for i in range(replayed_exps.shape[0]):\n",
    "        hmap[replayed_exps[i, 0], sim] += 1\n",
    "\n",
    "hmap_avg = np.mean(hmap, axis=1)\n",
    "hmap_avg = hmap_avg.reshape(height, width)\n",
    "\n",
    "cmap = plt.get_cmap('Purples')\n",
    "trunc_cividis = truncate_colormap(cmap, 0.2, 0.8) # plasma 0.15 1.0\n",
    "\n",
    "fig, axes = get_fixed_size_figax(nrow=1, ncol=3, figsize=(22, 6))\n",
    "\n",
    "# Schematic\n",
    "ax = axes[0]\n",
    "ax.set_aspect('equal')\n",
    "ax.set_axis_off()\n",
    "bottleneck.draw(use_reachability=True, ax=ax, wall_width=1)\n",
    "\n",
    "# Asymptotic need\n",
    "ax = axes[1]\n",
    "meta_need = np.mean(needs, axis=1)\n",
    "meta_gain = np.mean(gains, axis=1)\n",
    "meta_MEVB = np.mean(all_MEVBs, axis=1)\n",
    "plot_state_metric(bottleneck, np.average(meta_need[-1, :, :], weights=init_state_dist, axis=0), save=False, ax=ax,\n",
    "                 wall_width=1, custom_cmap=trunc_cividis)\n",
    "\n",
    "# Simulated replay distribution\n",
    "ax = axes[2]\n",
    "plot_state_metric(bottleneck, hmap_avg.reshape(-1), save=False, ax=ax, wall_width=1, custom_cmap=trunc_cividis)\n",
    "\n",
    "# Save\n",
    "fig.savefig('./figs/fig2/bottleneck_all_purples.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Supp. fig. comparison of need to betweenness-centrality in bottleneck chamber*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.get_cmap('Purples')\n",
    "trunc_cividis = truncate_colormap(cmap, 0.2, 0.8) # plasma 0.15 1.0\n",
    "\n",
    "fig, axes = get_fixed_size_figax(nrow=1, ncol=2, figsize=(22, 6))\n",
    "\n",
    "# Betweenness centrality\n",
    "ax = axes[0]\n",
    "ax.set_aspect('equal')\n",
    "ax.set_axis_off()\n",
    "\n",
    "bottleneck_A = bottleneck.generate_adjacency_matrix(allow_self_loops=True, allow_multiloops=True)\n",
    "for i in range(num_states):\n",
    "    if i not in valid_states:\n",
    "        bottleneck_A[i, :] = 0\n",
    "        \n",
    "# betweenness centrality\n",
    "bc = betweenness_centrality(bottleneck_A, convert_unweighted=True)\n",
    "plot_state_metric(bottleneck, bc, save=False, ax=ax,\n",
    "                 wall_width=1, custom_cmap=trunc_cividis)\n",
    "\n",
    "# Asymptotic need\n",
    "ax = axes[1]\n",
    "meta_need = np.mean(needs, axis=1)\n",
    "meta_gain = np.mean(gains, axis=1)\n",
    "meta_MEVB = np.mean(all_MEVBs, axis=1)\n",
    "plot_state_metric(bottleneck, np.average(meta_need[-1, :, :], weights=init_state_dist, axis=0), save=False, ax=ax,\n",
    "                 wall_width=1, custom_cmap=trunc_cividis)\n",
    "\n",
    "fig.savefig('./figs/supp_figs/bottleneck_need_BC.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 2c, Schapiro community graph maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_replay = False\n",
    "num_sims = 200\n",
    "start = 0\n",
    "\n",
    "# Physics\n",
    "width = 5\n",
    "height = 5\n",
    "num_states = width * height\n",
    "\n",
    "## Build object\n",
    "# Walls\n",
    "top = width // 2\n",
    "left = twod_oned(0, height // 2, width)\n",
    "right = twod_oned(width - 1, height // 2, width)\n",
    "bottom = twod_oned(width // 2, height - 1, width)\n",
    "middle = twod_oned(width // 2, height // 2, width)\n",
    "\n",
    "walls = [(top, 0), (top, 2), (top, 3)]\n",
    "walls.extend([(left, 1), (left, 2), (left, 3)])\n",
    "walls.extend([(right, 0), (right, 1), (right, 3)])\n",
    "walls.extend([(bottom, 0), (bottom, 1), (bottom, 2)])\n",
    "walls.extend([(middle, 0), (middle, 1), (middle, 2), (middle, 3)])\n",
    "\n",
    "# Valid states\n",
    "valid_states = np.arange(num_states)\n",
    "mask = np.ones(len(valid_states), dtype=bool)\n",
    "mask[[top, left, right, bottom, middle]] = False\n",
    "valid_states = valid_states[mask]\n",
    "\n",
    "# Various parameters\n",
    "all_states = np.zeros(num_states)\n",
    "all_states[valid_states] = 1 / len(valid_states)\n",
    "one_state = np.zeros(num_states)\n",
    "one_state[0] = 1\n",
    "init_state_dist = all_states\n",
    "\n",
    "gw = GridWorld(width, height, walls=walls, init_state_distribution=init_state_dist)\n",
    "all_experiences = gw.get_all_transitions()\n",
    "T = gw.transitions\n",
    "\n",
    "# Agent parameters\n",
    "corner_goals = np.array([width - 1, height * width - 1]) # Non-start corners\n",
    "all_goals = np.arange(num_states)\n",
    "valid_goals = valid_states\n",
    "goals = valid_goals\n",
    "\n",
    "alpha = 1.0\n",
    "gamma = 0.95\n",
    "num_replay_steps = 1000\n",
    "\n",
    "if run_replay:\n",
    "    print('running...')\n",
    "    for i in range(start, num_sims):\n",
    "        print(i, end=', ')\n",
    "        \n",
    "        # Set up agent\n",
    "        ga = GeodesicAgent(gw.num_states, gw.num_actions, goals, T, alpha=alpha, gamma=gamma,\n",
    "                           s0_dist=init_state_dist)\n",
    "        ga.curr_state = 0\n",
    "        ga.remember(all_experiences) # Pre-load our agent with all possible memories\n",
    "\n",
    "        ## Run replay\n",
    "        replayed_exps, stats_for_nerds, backups = ga.replay(num_steps=num_replay_steps, verbose=True, prospective=True)\n",
    "        needs, trans_needs, gains, all_MEVBs = stats_for_nerds\n",
    "        np.savez('./Data/schapiro/schapiro_data%d.npz' % i, replayed_exps=replayed_exps, needs=needs,\n",
    "                                                               trans_needs=trans_needs, gains=gains, all_MEVBs=all_MEVBs)\n",
    "    print('ran!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figure 2b, schematic, asymptotic need, and empirical replay distribution in bottleneck chamber*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hmap = np.zeros((num_states, num_sims))\n",
    "for sim in range(num_sims):\n",
    "    d = np.load('./Data/schapiro/schapiro_data%d.npz' % sim)\n",
    "    replayed_exps = d['replayed_exps']\n",
    "    for i in range(replayed_exps.shape[0]):\n",
    "        hmap[replayed_exps[i, 0], sim] += 1\n",
    "\n",
    "hmap_avg = np.mean(hmap, axis=1)\n",
    "hmap_avg = hmap_avg.reshape(height, width)\n",
    "\n",
    "cmap = plt.get_cmap('Purples')\n",
    "trunc_map = truncate_colormap(cmap, 0.2, 0.8) # plasma 0.15 1.0\n",
    "\n",
    "fig, axes = get_fixed_size_figax(nrow=1, ncol=3)\n",
    "\n",
    "# Schematic\n",
    "ax = axes[0]\n",
    "ax.set_aspect('equal')\n",
    "ax.set_axis_off()\n",
    "gw.draw(use_reachability=True, ax=ax, wall_width=1)\n",
    "\n",
    "# Asymptotic need\n",
    "ax = axes[1]\n",
    "d = np.load('./Data/schapiro/schapiro_data0.npz')\n",
    "needs = d['needs']\n",
    "meta_need = np.mean(needs, axis=1)\n",
    "avg_need = np.average(meta_need[-1, :, :], weights=init_state_dist, axis=0)\n",
    "plot_state_metric(gw, avg_need.reshape(-1), save=False, ax=ax, wall_width=1, custom_cmap=trunc_map)\n",
    "\n",
    "# Simulated replay distribution\n",
    "ax = axes[2]\n",
    "plot_state_metric(gw, hmap_avg.reshape(-1), save=False, ax=ax, wall_width=1, custom_cmap=trunc_map)\n",
    "\n",
    "# Save\n",
    "fig.savefig('./figs/fig2/schapiro_all_purples.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Supp. fig. comparison of need to betweenness-centrality in Schapiro community graph maze*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.get_cmap('Purples')\n",
    "trunc_map = truncate_colormap(cmap, 0.2, 0.8) # plasma 0.15 1.0\n",
    "\n",
    "fig, axes = get_fixed_size_figax(nrow=1, ncol=2)\n",
    "\n",
    "# Betweenness centrality\n",
    "ax = axes[0]\n",
    "ax.set_aspect('equal')\n",
    "ax.set_axis_off()\n",
    "\n",
    "gw_A = gw.generate_adjacency_matrix(allow_self_loops=True, allow_multiloops=True)\n",
    "for i in range(num_states):\n",
    "    if i not in valid_states:\n",
    "        gw_A[i, :] = 0\n",
    "        \n",
    "# betweenness centrality\n",
    "bc = betweenness_centrality(gw_A, convert_unweighted=True)\n",
    "plot_state_metric(gw, bc, save=False, ax=ax,\n",
    "                 wall_width=1, custom_cmap=trunc_cividis)\n",
    "\n",
    "# Asymptotic need\n",
    "ax = axes[1]\n",
    "d = np.load('./Data/schapiro/schapiro_data0.npz')\n",
    "needs = d['needs']\n",
    "meta_need = np.mean(needs, axis=1)\n",
    "avg_need = np.average(meta_need[-1, :, :], weights=init_state_dist, axis=0)\n",
    "plot_state_metric(gw, avg_need.reshape(-1), save=False, ax=ax, wall_width=1, custom_cmap=trunc_map)\n",
    "\n",
    "# Save\n",
    "fig.savefig('./figs/supp_figs/schapiro_need_BC.pdf', transparent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
